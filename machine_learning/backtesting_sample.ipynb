{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting & Strategy Validation\n",
    "\n",
    "This notebook demonstrates a framework for backtesting the performance of a trained machine learning model on out-of-sample historical data. The process simulates trade execution on a minute-by-minute basis, accounting for realistic costs like the bid-ask spread, and provides a clear analysis of the strategy's profitability.\n",
    "\n",
    "The key steps are:\n",
    "1.  **Setup:** Load the trained Keras model, data scalers, and helper functions.\n",
    "2.  **Data Loading:** Load a dataset that the model has not been trained on.\n",
    "3.  **Simulation Loop:** Iterate through the dataset minute-by-minute, maintaining a buffer of recent data to feed the model.\n",
    "4.  **Inference & Trade Logic:** For each minute, preprocess the data, generate a prediction, and execute trades based on a defined strategy.\n",
    "5.  **Performance Analysis:** Calculate and visualize the portfolio's profit and loss (PnL) over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup: Load Model and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from collections import deque\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Load key components and helper functions from the training script ---\n",
    "from model_training import (\n",
    "    add_features_to_single_batch, \n",
    "    scale_dataframe, \n",
    "    classifier_mapping,\n",
    "    SEQ_LEN,\n",
    "    FUTURE_PERIOD_PREDICT\n",
    ")\n",
    "\n",
    "# --- Load the pre-trained model and scalers ---\n",
    "MODEL_PATH = 'path/to/your/model_checkpoint.keras'\n",
    "SCALER_PATH = 'path/to/your/saved_scalers.joblib'\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "scalers = joblib.load(SCALER_PATH)\n",
    "\n",
    "print(\"Model and scalers loaded successfully.\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Loading\n",
    "\n",
    "Load the out-of-sample dataset. This data was not used during the training or validation phases to ensure the backtest provides an unbiased estimate of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/market/unseen_data.parquet'\n",
    "test_df = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "# For demonstration, we'll use a small slice of the data\n",
    "backtest_data = test_df.head(1000).copy()\n",
    "\n",
    "print(f\"Loaded backtest data with shape: {backtest_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simulation Loop & Inference\n",
    "\n",
    "This is the core of the backtest. We iterate through each minute, simulate the flow of real-time data, and make trading decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Backtest Configuration ---\n",
    "\n",
    "trade_instrument = 'GBPUSD' # The instrument we are trading\n",
    "trade_threshold = 0.50 # Confidence threshold to place a trade\n",
    "minute_buffer = deque(maxlen=SEQ_LEN) # Buffer to hold recent data for model input\n",
    "pnl_history = [] # List to store results of each closed trade\n",
    "\n",
    "active_position = None # To hold info about the current open trade\n",
    "\n",
    "# --- Main Simulation Loop ---\n",
    "for timestamp, row in backtest_data.iterrows():\n",
    "    minute_buffer.append(row)\n",
    "\n",
    "    # We need a full buffer to make a prediction\n",
    "    if len(minute_buffer) < SEQ_LEN:\n",
    "        continue\n",
    "\n",
    "    # 1. Prepare the data batch for the model\n",
    "    input_batch_df = pd.DataFrame(list(minute_buffer))\n",
    "    features_df = add_features_to_single_batch(input_batch_df.copy())\n",
    "    \n",
    "    # Drop rows with NaNs from feature calculation warm-up\n",
    "    features_df.dropna(inplace=True)\n",
    "    if len(features_df) < (SEQ_LEN - FUTURE_PERIOD_PREDICT):\n",
    "        continue # Not enough data after processing\n",
    "\n",
    "    # 2. Scale the data using the pre-fitted scalers\n",
    "    scaled_df, _ = scale_dataframe(features_df.copy(), scalers, 'validation')\n",
    "    model_input = scaled_df.drop(columns=['target']).values\n",
    "\n",
    "    # 3. Generate a prediction\n",
    "    prediction = model.predict(np.expand_dims(model_input, axis=0), verbose=0)[0]\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    predicted_confidence = prediction[predicted_class]\n",
    "\n",
    "    # --- Trade Execution Logic ---\n",
    "    \n",
    "    # 4. Check if we should close an existing position\n",
    "    if active_position and (timestamp - active_position['entry_time']).total_seconds() >= (FUTURE_PERIOD_PREDICT * 60):\n",
    "        if active_position['direction'] == 'LONG':\n",
    "            exit_price = row[f'{trade_instrument}_close_price__bid_level_1'] # Sell at the bid\n",
    "            pnl = exit_price - active_position['entry_price']\n",
    "        else: # SHORT\n",
    "            exit_price = row[f'{trade_instrument}_close_price__ask_level_1'] # Buy back at the ask\n",
    "            pnl = active_position['entry_price'] - exit_price\n",
    "        \n",
    "        pnl_history.append({'pnl': pnl, 'exit_time': timestamp})\n",
    "        active_position = None # Position is now closed\n",
    "\n",
    "    # 5. Check if we should open a new position\n",
    "    if not active_position and predicted_confidence > trade_threshold:\n",
    "        direction = None\n",
    "        if classifier_mapping[predicted_class] in ['strong upward', 'mild upward']:\n",
    "            direction = 'LONG'\n",
    "            entry_price = row[f'{trade_instrument}_open_price__ask_level_1'] # Buy at the ask\n",
    "        elif classifier_mapping[predicted_class] in ['strong downward', 'mild downward']:\n",
    "            direction = 'SHORT'\n",
    "            entry_price = row[f'{trade_instrument}_open_price__bid_level_1'] # Sell at the bid\n",
    "        \n",
    "        if direction:\n",
    "            active_position = {\n",
    "                'entry_time': timestamp,\n",
    "                'entry_price': entry_price,\n",
    "                'direction': direction\n",
    "            }\n",
    "\n",
    "print(\"Backtest simulation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Performance Analysis\n",
    "\n",
    "With the simulation finished, we can now analyze the results to understand the strategy's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pnl_history:\n",
    "    print(\"No trades were executed during the backtest.\")\n",
    "else:\n",
    "    results_df = pd.DataFrame(pnl_history)\n",
    "    results_df.set_index('exit_time', inplace=True)\n",
    "\n",
    "    # Calculate PnL in pips (assuming non-JPY pair)\n",
    "    results_df['pnl_pips'] = results_df['pnl'] * 10000\n",
    "    results_df['cumulative_pnl_pips'] = results_df['pnl_pips'].cumsum()\n",
    "\n",
    "    # --- Print Key Metrics ---\n",
    "    total_trades = len(results_df)\n",
    "    winning_trades = (results_df['pnl_pips'] > 0).sum()\n",
    "    win_rate = (winning_trades / total_trades) * 100 if total_trades > 0 else 0\n",
    "    total_pnl = results_df['pnl_pips'].sum()\n",
    "\n",
    "    print(f\"--- Backtest Results ---\")\n",
    "    print(f\"Total Trades: {total_trades}\")\n",
    "    print(f\"Win Rate: {win_rate:.2f}%\")\n",
    "    print(f\"Total PnL: {total_pnl:.2f} pips\")\n",
    "\n",
    "    # --- Plot Cumulative PnL ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    results_df['cumulative_pnl_pips'].plot(ax=ax, lw=2)\n",
    "\n",
    "    ax.set_title('Cumulative PnL Over Time', fontsize=16)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Cumulative PnL (pips)')\n",
    "    ax.axhline(0, color='black', linestyle='--', lw=1)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
